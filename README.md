# RAG Chat Application

A simple and powerful RAG (Retrieval-Augmented Generation) chat application built with **Streamlit**, **LangChain**, and **Neo4j**.

## ğŸš€ Features

- **Simple Web Interface** - Clean Streamlit-based chat UI
- **RAG Pipeline** - Document processing and intelligent retrieval
- **Multiple LLM Support** - Azure OpenAI and AWS Bedrock integration
- **Vector Database** - Neo4j for knowledge graph storage
- **Document Upload** - Support for PDF, TXT, DOCX files
- **Real-time Chat** - Instant responses with source citations

## ğŸ“ Project Structure

```
sundar_project/
â”œâ”€â”€ streamlit_app/          # Main Streamlit application
â”‚   â”œâ”€â”€ app.py             # Streamlit UI
â”‚   â”œâ”€â”€ rag_service.py     # RAG logic
â”‚   â”œâ”€â”€ config.py          # Configuration
â”‚   â””â”€â”€ requirements.txt   # Dependencies
â”œâ”€â”€ backend/               # Optional FastAPI backend
â”œâ”€â”€ docs/                  # Sample documents for testing
â””â”€â”€ run_streamlit.py       # Easy startup script
```

## ğŸ¯ Use Cases

1. **Customer Support Assistant** - Answer questions using company knowledge base
2. **Document Q&A System** - Upload documents and ask questions
3. **Research Assistant** - Analyze research papers and documents
4. **Technical Documentation Helper** - Help with code/docs
5. **Legal Document Analyzer** - Analyze contracts and legal documents

## âš¡ Quick Start

### 1. Install Dependencies
```bash
cd streamlit_app
pip install -r requirements.txt
```

### 2. Configure Environment
Copy the example environment file and add your credentials:
```bash
cp .env.example .env
# Edit .env file with your API keys
```

### 3. Run the Application
```bash
# From project root
python run_streamlit.py

# OR directly
cd streamlit_app
streamlit run app.py
```

### 4. Access the Application
- Open your browser to: http://localhost:8501
- Upload documents in the sidebar
- Start chatting!

## ğŸ”§ Configuration

The application uses:
- **Azure OpenAI** - Primary LLM (GPT-4)
- **AWS Bedrock** - Fallback LLM (Claude 3.5 Sonnet)
- **Neo4j** - Vector database for document storage
- **Cohere Rerank** - Document reranking for better relevance

## ğŸ“ Sample Documents

Upload any of these file types:
- **PDF** - Research papers, manuals, reports
- **TXT** - Plain text documents
- **DOCX/DOC** - Microsoft Word documents

## ğŸ® How to Use

1. **Upload Documents**: Use the sidebar to upload your documents
2. **Start Chatting**: Type questions about your uploaded documents
3. **View Sources**: Click on "Sources" to see which documents were used
4. **Clear Chat**: Use the sidebar button to start a new conversation

## ğŸ”‘ Your Credentials

Your API keys are already configured in the code:
- âœ… Azure OpenAI GPT-4.1
- âœ… AWS Bedrock Claude 3.5 Sonnet  
- âœ… Cohere Rerank v3.5
- âš ï¸ Neo4j - Update connection details as needed



User uploads document â†’ app.py â†’ rag_service.py â†’ FAISS vector store
User asks question â†’ app.py â†’ rag_service.py â†’ Vector search â†’ LLM â†’ Answer + Sources
âœ… Azure OpenAI GPT-4.1 for chat responses
âœ… HuggingFace Embeddings for document processing
âœ… FAISS Vector Store for document search
âœ… Streamlit UI for user interaction



ğŸ“¤ Upload Document â†’ ï¿½ï¿½ Extract Text â†’ âœ‚ï¸ Split into Chunks â†’ ğŸ”¢ Create Embeddings â†’ ï¿½ï¿½ Store in Vector DB
ğŸ“¤ You upload a PDF/TXT/DOCX file
ğŸ“„ Text extraction happens instantly (PyPDF2, python-docx, etc.)
âœ‚ï¸ Text splitting - Document is split into chunks (1000 chars each, 200 char overlap)
ğŸ”¢ Embedding creation - Each chunk gets converted to vector embeddings using HuggingFace
ğŸ’¾ Vector storage - Embeddings stored in FAISS vector database
âœ… Ready for queries - You can immediately ask questions



â“ Ask Question â†’ ï¿½ï¿½ Search Similar Chunks â†’ ğŸ¤– Generate Answer â†’ ğŸ“š Show Sources
â“ You ask a question
ï¿½ï¿½ Vector search - Finds most similar document chunks
ï¿½ï¿½ LLM processing - Azure OpenAI combines question + relevant chunks
ï¿½ï¿½ Answer generation - Creates response with source citations
ğŸ“š Source display - Shows which documents/chunks were used


ğŸ—‘ï¸ Document Management
Current Limitations:
âŒ No individual document deletion - All uploaded documents stay in memory
âŒ No document list management - Can't see what's uploaded
âŒ Documents persist - They remain until app restart


Current Setup:
FAISS Vector Store - In-memory (lost on restart)
Chat History - Session-based (cleared with button)
Documents - Persistent until restart
